{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71afe433",
   "metadata": {},
   "source": [
    "# AT&T — Détection de SPAM SMS (Deep Learning)\n",
    "\n",
    "Notebook en français (PyTorch) pour classifier des SMS en **spam** ou **ham** à partir du contenu.\n",
    "\n",
    "**Livrable** : prétraitement + entraînement deep learning + performance clairement affichée (Accuracy, Precision, Recall, F1 + matrice de confusion)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4c6d9b",
   "metadata": {},
   "source": [
    "## 1. Imports et paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ce2f514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.2.0\n",
      "Device : cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"Device :\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d93dfb",
   "metadata": {},
   "source": [
    "## 2. Chargement et inspection rapide\n",
    "\n",
    "Le dataset contient typiquement `v1` (label) et `v2` (texte). On garde uniquement ces colonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bfed261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille : (5572, 2)\n",
      "Taux de spam : 0.13406317300789664\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DATA_PATH = \"spam.csv\"  # le fichier doit être dans le même dossier que ce notebook\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, encoding=\"latin-1\")\n",
    "df = df[[\"v1\", \"v2\"]].rename(columns={\"v1\": \"label\", \"v2\": \"text\"})\n",
    "df[\"label\"] = df[\"label\"].map({\"ham\": 0, \"spam\": 1}).astype(int)\n",
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "\n",
    "display(df.head())\n",
    "print(\"Taille :\", df.shape)\n",
    "print(\"Taux de spam :\", df[\"label\"].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ba51e5",
   "metadata": {},
   "source": [
    "## 3. Split Train / Validation / Test (stratifié)\n",
    "\n",
    "On stratifie à cause du déséquilibre de classes (spam minoritaire)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2065bd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3565, 2) | spam: 0.13408134642356243\n",
      "Val  : (892, 2) | spam: 0.13452914798206278\n",
      "Test : (1115, 2) | spam: 0.1336322869955157\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    df, test_size=0.20, random_state=SEED, stratify=df[\"label\"]\n",
    ")\n",
    "train_df, val_df = train_test_split(\n",
    "    train_df, test_size=0.20, random_state=SEED, stratify=train_df[\"label\"]\n",
    ")\n",
    "\n",
    "print(\"Train:\", train_df.shape, \"| spam:\", train_df[\"label\"].mean())\n",
    "print(\"Val  :\", val_df.shape,   \"| spam:\", val_df[\"label\"].mean())\n",
    "print(\"Test :\", test_df.shape,  \"| spam:\", test_df[\"label\"].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af30f58",
   "metadata": {},
   "source": [
    "## 4. Prétraitement : tokenisation + vocabulaire\n",
    "\n",
    "On commence simple : tokens alphanumériques en minuscules. Vocabulaire construit sur **train uniquement**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f1edcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulaire: 3251\n",
      "Exemple tokens: ['what', 'to', 'think', 'no', 'one', 'saying', 'clearly', 'ok', 'leave', 'no', 'need', 'to', 'ask', 'her', 'i', 'will', 'go', 'if', 'she', 'come']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import Counter\n",
    "\n",
    "TOKEN_RE = re.compile(r\"[A-Za-z0-9']+\")\n",
    "\n",
    "def tokenize(s: str):\n",
    "    return TOKEN_RE.findall(s.lower())\n",
    "\n",
    "counter = Counter()\n",
    "for t in train_df[\"text\"]:\n",
    "    counter.update(tokenize(t))\n",
    "\n",
    "min_freq = 2\n",
    "special = [\"<pad>\", \"<unk>\"]\n",
    "itos = special + [w for w, c in counter.items() if c >= min_freq]\n",
    "stoi = {w: i for i, w in enumerate(itos)}\n",
    "\n",
    "vocab_size = len(itos)\n",
    "pad_idx = stoi[\"<pad>\"]\n",
    "unk_idx = stoi[\"<unk>\"]\n",
    "\n",
    "def numericalize(tokens):\n",
    "    return [stoi.get(tok, unk_idx) for tok in tokens]\n",
    "\n",
    "print(\"Vocabulaire:\", vocab_size)\n",
    "print(\"Exemple tokens:\", tokenize(train_df[\"text\"].iloc[0])[:20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087e68c5",
   "metadata": {},
   "source": [
    "## 5. Dataset PyTorch + DataLoaders (EmbeddingBag)\n",
    "\n",
    "EmbeddingBag nécessite des tokens aplatis + des offsets (très rapide pour un baseline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08d86957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: DataLoaders prêts\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class SMSDataset(Dataset):\n",
    "    def __init__(self, frame: pd.DataFrame):\n",
    "        self.labels = torch.tensor(frame[\"label\"].values, dtype=torch.long)\n",
    "        # pré-calcul (accélère)\n",
    "        self.seqs = [\n",
    "            torch.tensor(numericalize(tokenize(t)), dtype=torch.long)\n",
    "            for t in frame[\"text\"].tolist()\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.seqs[idx], self.labels[idx]\n",
    "\n",
    "train_ds = SMSDataset(train_df)\n",
    "val_ds   = SMSDataset(val_df)\n",
    "test_ds  = SMSDataset(test_df)\n",
    "\n",
    "def collate_embeddingbag(batch):\n",
    "    labels = torch.stack([b[1] for b in batch])\n",
    "    flat = torch.cat([b[0] for b in batch])\n",
    "    offsets = torch.tensor([0] + [len(b[0]) for b in batch[:-1]]).cumsum(0)\n",
    "    return flat, offsets, labels\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=256, shuffle=True,  collate_fn=collate_embeddingbag)\n",
    "val_dl   = DataLoader(val_ds,   batch_size=512, shuffle=False, collate_fn=collate_embeddingbag)\n",
    "test_dl  = DataLoader(test_ds,  batch_size=512, shuffle=False, collate_fn=collate_embeddingbag)\n",
    "\n",
    "print(\"OK: DataLoaders prêts\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dd81ff",
   "metadata": {},
   "source": [
    "## 6. Modèle deep learning baseline : EmbeddingBag (style fastText)\n",
    "\n",
    "**Pourquoi** : rapide + robuste sur texte court.\n",
    "\n",
    "**Limite** : pas de notion d'ordre des mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c57d745",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mlflow310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Époque 01 | Val: acc=0.8139 prec=0.1290 rec=0.0667 f1=0.0879\n",
      "Époque 02 | Val: acc=0.8520 prec=0.1667 rec=0.0250 f1=0.0435\n",
      "Époque 03 | Val: acc=0.8711 prec=0.7778 rec=0.0583 f1=0.1085\n",
      "Époque 04 | Val: acc=0.8800 prec=0.8421 rec=0.1333 f1=0.2302\n",
      "Époque 05 | Val: acc=0.9092 prec=0.9535 rec=0.3417 f1=0.5031\n",
      "Époque 06 | Val: acc=0.9428 prec=0.9481 rec=0.6083 f1=0.7411\n",
      "\n",
      "=== PERFORMANCE TEST ===\n",
      "Accuracy=0.9426 | Precision=0.9381 | Recall=0.6107 | F1=0.7398\n",
      "Matrice de confusion [ [TN FP] [FN TP] ]:\n",
      " [[960   6]\n",
      " [ 58  91]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class FastTextClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_dim: int = 64, num_classes: int = 2):\n",
    "        super().__init__()\n",
    "        self.emb = nn.EmbeddingBag(vocab_size, emb_dim, mode=\"mean\")\n",
    "        self.fc = nn.Linear(emb_dim, num_classes)\n",
    "\n",
    "    def forward(self, flat, offsets):\n",
    "        x = self.emb(flat, offsets)\n",
    "        return self.fc(x)\n",
    "\n",
    "def metrics_binary(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=\"binary\", zero_division=0\n",
    "    )\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return acc, prec, rec, f1, cm\n",
    "\n",
    "def train_epoch(model, dl, optimizer):\n",
    "    model.train(True)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    for flat, offsets, y in dl:\n",
    "        flat, offsets, y = flat.to(device), offsets.to(device), y.to(device)\n",
    "        logits = model(flat, offsets)\n",
    "        loss = loss_fn(logits, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def predict(model, dl):\n",
    "    model.eval()\n",
    "    ys, ps = [], []\n",
    "    with torch.no_grad():\n",
    "        for flat, offsets, y in dl:\n",
    "            logits = model(flat.to(device), offsets.to(device))\n",
    "            pred = logits.argmax(1).cpu().numpy()\n",
    "            ps.extend(pred.tolist())\n",
    "            ys.extend(y.numpy().tolist())\n",
    "    return np.array(ys), np.array(ps)\n",
    "\n",
    "model = FastTextClassifier(vocab_size=vocab_size, emb_dim=64).to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=3e-3)\n",
    "\n",
    "EPOCHS = 6\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_epoch(model, train_dl, opt)\n",
    "    yv, pv = predict(model, val_dl)\n",
    "    acc, prec, rec, f1, _ = metrics_binary(yv, pv)\n",
    "    print(f\"Époque {epoch:02d} | Val: acc={acc:.4f} prec={prec:.4f} rec={rec:.4f} f1={f1:.4f}\")\n",
    "\n",
    "yt, pt = predict(model, test_dl)\n",
    "acc, prec, rec, f1, cm = metrics_binary(yt, pt)\n",
    "\n",
    "print(\"\\n=== PERFORMANCE TEST ===\")\n",
    "print(f\"Accuracy={acc:.4f} | Precision={prec:.4f} | Recall={rec:.4f} | F1={f1:.4f}\")\n",
    "print(\"Matrice de confusion [ [TN FP] [FN TP] ]:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d631f0",
   "metadata": {},
   "source": [
    "## 7. Discussion (principes & trade-offs)\n",
    "\n",
    "- Dataset **déséquilibré** : on privilégie aussi Precision/Recall/F1.\n",
    "- Baseline EmbeddingBag : **très rapide** et souvent étonnamment performant.\n",
    "- Améliorations possibles : n-grammes, BiLSTM, ou **transfer learning** (Transformers) si le contexte le permet.\n",
    "- En production : calibration du seuil (coût FP/FN), monitoring de drift, retraining régulier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f8faa8",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "Notebook prêt pour la soutenance : pipeline complet + résultats sur le jeu de test."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
